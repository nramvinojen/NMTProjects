{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "import string\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "               # open the file as read only\n",
    "               file = open(filename, mode='rt', encoding='utf-8')\n",
    "               # read all text\n",
    "               text = file.read()\n",
    "               # close the file\n",
    "               file.close()\n",
    "               return text\n",
    "def to_lines(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    return lines\n",
    " \n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "               lines = doc.strip().split('\\n')\n",
    "               pairs = [line.split('\\t') for line in  lines]\n",
    "               return pairs\n",
    " \n",
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "   cleaned = list()\n",
    "   # prepare regex for char filtering\n",
    "   re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "   # prepare translation table for removing punctuation\n",
    "   table = str.maketrans('', '', string.punctuation)\n",
    "   for pair in lines:\n",
    "      clean_pair = list()\n",
    "      for line in pair:\n",
    "         # normalize unicode characters\n",
    "         line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "         line = line.decode('UTF-8')\n",
    "         # tokenize on white space\n",
    "         line = line.split()\n",
    "         # convert to lowercase\n",
    "         line = [word.lower() for word in line]\n",
    "         # remove punctuation from each token\n",
    "         line = [word.translate(table) for word in line]\n",
    "         # remove non-printable chars form each token\n",
    "         line = [re_print.sub('', w) for w in line]\n",
    "         # remove tokens with numbers in them\n",
    "         line = [word for word in line if word.isalpha()]\n",
    "         # store as string\n",
    "         clean_pair.append(' '.join(line))\n",
    "      cleaned.append(clean_pair)\n",
    "   return array(cleaned)\n",
    " \n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "               dump(sentences, open(filename, 'wb'))\n",
    "               print('Saved: %s' % filename)\n",
    "            \n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    \n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('Dataset/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('war', 1.0),\n",
       " ('wars', 0.748465895652771),\n",
       " ('War', 0.6410670280456543),\n",
       " ('invasion', 0.5892110466957092),\n",
       " ('Persian_Gulf_War', 0.5890660285949707),\n",
       " ('Vietnam_War', 0.5886474847793579),\n",
       " ('Iraq', 0.588599443435669),\n",
       " ('unwinnable_quagmire', 0.5681803226470947),\n",
       " ('un_winnable', 0.560634970664978),\n",
       " ('occupation', 0.5506216287612915)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=word_vectors['war']\n",
    "word_vectors.most_similar(positive = [a])#[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.most_similar(positive = [a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = 'dev_en.txt'\n",
    "doc_in = load_doc(filename)\n",
    "filename = 'dev_sen.txt'\n",
    "doc_out = load_doc(filename)\n",
    "lines_in = to_lines(doc_in)\n",
    "lines_out = to_lines(doc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_in = np.asarray(lines_in)\n",
    "lines_out = np.asarray(lines_out)\n",
    "\n",
    "pairs = np.column_stack((lines_out, lines_in))\n",
    "pairs = pairs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marin, Mendocino, Lake, Napa, Solano and Contra Costa are all adjacent countries.',\n",
       " 'Adjacent counties are Marin ( to the south ) , Mendocino ( to the north ) , Lake ( northeast ) , Napa ( to the east ) , and Solano and Contra Costa ( to the southeast ) .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[2]\n",
    "#type(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SimpleEnglish-English.pkl\n"
     ]
    }
   ],
   "source": [
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs[:200])\n",
    "# save clean pairs to file\n",
    "save_clean_data(clean_pairs, 'SimpleEnglish-English.pkl')\n",
    "# spot check\n",
    "#for i in range(100):\n",
    "  # print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SimpleEnglish-English-both.pkl\n",
      "Saved: SimpleEnglish-English-train.pkl\n",
      "Saved: SimpleEnglish-English-val.pkl\n",
      "Saved: SimpleEnglish-English-test.pkl\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "raw_dataset = load_clean_sentences('SimpleEnglish-English.pkl')\n",
    " \n",
    "# reduce dataset size\n",
    "n_sentences = 200\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test \n",
    "train, val, test = dataset[:150], dataset[150:170], dataset[170:] #Added Validation set - avs\n",
    "# save\n",
    "save_clean_data(dataset, 'SimpleEnglish-English-both.pkl')\n",
    "save_clean_data(train, 'SimpleEnglish-English-train.pkl')\n",
    "save_clean_data(val, 'SimpleEnglish-English-val.pkl')\n",
    "save_clean_data(test, 'SimpleEnglish-English-test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dataset = load_clean_sentences('SimpleEnglish-English-both.pkl')\n",
    "train = load_clean_sentences('SimpleEnglish-English-train.pkl')\n",
    "val = load_clean_sentences('SimpleEnglish-English-val.pkl') #added clean for val - avs\n",
    "test = load_clean_sentences('SimpleEnglish-English-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleEng Vocabulary Size: 517\n",
      "SimpleEng Max Length: 44\n",
      "English Vocabulary Size: 288\n",
      "English Max Length: 35\n"
     ]
    }
   ],
   "source": [
    "# prepare SimpleEng tokenizer\n",
    "sen_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "sen_vocab_size = len(sen_tokenizer.word_index) + 1\n",
    "sen_length = max_length(dataset[:, 0])\n",
    "print('SimpleEng Vocabulary Size: %d' % sen_vocab_size)\n",
    "print('SimpleEng Max Length: %d' % (sen_length))\n",
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 1])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 1])\n",
    "trainY = encode_sequences(sen_tokenizer, sen_length, train[:, 0])\n",
    "trainY = encode_output(trainY, sen_vocab_size)\n",
    "# prepare validation data\n",
    "valX = encode_sequences(eng_tokenizer, eng_length, val[:, 1]) #added tokeniser for val set - avs\n",
    "valY = encode_sequences(sen_tokenizer, sen_length, val[:, 0])\n",
    "valY = encode_output(valY, sen_vocab_size)\n",
    "# prepare test data\n",
    "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 1])\n",
    "testY = encode_sequences(sen_tokenizer, sen_length, test[:, 0])\n",
    "testY = encode_output(testY, sen_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 35, 256)           73728     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_6 (RepeatVecto (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 44, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 44, 517)           132869    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 44, 517)           0         \n",
      "=================================================================\n",
      "Total params: 1,257,221\n",
      "Trainable params: 1,257,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed, Dense, Dropout\n",
    "\n",
    "\n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    model.add(Dropout(0.3))\n",
    "    return model\n",
    " \n",
    "# define model\n",
    "model = define_model(eng_vocab_size, sen_vocab_size, eng_length, sen_length, 256)\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 20 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-942318a9ad0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2931\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2932\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2933\u001b[1;33m                                 session)\n\u001b[0m\u001b[0;32m   2934\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   2883\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2884\u001b[0m         \u001b[1;31m# Create callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2885\u001b[1;33m         \u001b[0mcallable_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2886\u001b[0m         \u001b[1;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m         \u001b[1;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \"\"\"\n\u001b[0;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1444\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[1;32m-> 1446\u001b[1;33m             session._session, options_ptr)\n\u001b[0m\u001b[0;32m   1447\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=15, batch_size=64, validation_data=(valX, valY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxddZ3/8dcn92Zf2zRdU2ihpSvQllABHWVTiwuoVCwCBWXEBQZcR/g5zu83/n7O6OioOIJYBUVUFlmGqggICIKsbSnQvYW2NG3Tpk3TpFma7fP745ymt+lNmrS9ObnN+/l43MdZ7vec+7lpc9/5nnPP95i7IyIi0lsZURcgIiLpRcEhIiJ9ouAQEZE+UXCIiEifKDhERKRPFBwiItInCg6RFDKzX5nZ/+tl2w1mdv6R7kck1RQcIiLSJwoOERHpEwWHDHrhIaKvmdnrZtZgZreb2Qgz+7OZ1ZvZE2Y2JKH9hWa23MxqzexpM5uS8NxMM1sSbncvkNPltT5kZkvDbZ83s1MOs+bPmNk6M6sxs4VmNjpcb2b2QzPbbma7w/c0PXzuA2a2Iqxts5l99bB+YDLoKThEAhcD7wVOAj4M/Bn4X8Awgt+T6wHM7CTgbuCLQBnwCPAHM8sysyzgf4C7gKHA78P9Em47C7gD+CxQCvwMWGhm2X0p1MzOBf4DuAQYBWwE7gmffh/w7vB9lACfAHaGz90OfNbdC4HpwFN9eV2RfRQcIoH/dvdt7r4ZeBZ4yd1fdfe9wEPAzLDdJ4A/uftf3L0V+D6QC5wFnAFkAj9y91Z3vx94JeE1PgP8zN1fcvd2d78T2Btu1xeXAXe4+5KwvpuAM81sHNAKFAKTAXP3le6+NdyuFZhqZkXuvsvdl/TxdUUABYfIPtsS5puSLBeE86MJ/sIHwN07gE3AmPC5zX7gyKEbE+aPB74SHqaqNbNaYGy4XV90rWEPQa9ijLs/BfwEuAXYZmYLzKwobHox8AFgo5k9Y2Zn9vF1RQAFh0hfbSEIACA4p0Dw4b8Z2AqMCdftc1zC/Cbg2+5ekvDIc/e7j7CGfIJDX5sB3P3H7n4aMI3gkNXXwvWvuPtFwHCCQ2r39fF1RQAFh0hf3Qd80MzOM7NM4CsEh5ueB14A2oDrzSxuZh8DZids+3Pgc2b2jvAkdr6ZfdDMCvtYw++AT5nZjPD8yL8THFrbYGanh/vPBBqAZqA9PAdzmZkVh4fY6oD2I/g5yCCm4BDpA3dfDVwO/Dewg+BE+ofdvcXdW4CPAVcBuwjOhzyYsO0igvMcPwmfXxe27WsNTwLfBB4g6OWcCMwLny4iCKhdBIezdhKchwG4AthgZnXA58L3IdJnphs5iYhIX6jHISIifaLgEBGRPlFwiIhInyg4RESkT+JRF9Afhg0b5uPGjYu6DBGRtLJ48eId7l7Wdf2gCI5x48axaNGiqMsQEUkrZrYx2XodqhIRkT5RcIiISJ8oOEREpE8GxTmOZFpbW6msrKS5uTnqUlIqJyeH8vJyMjMzoy5FRI4RgzY4KisrKSwsZNy4cRw4mOmxw93ZuXMnlZWVjB8/PupyROQYMWgPVTU3N1NaWnrMhgaAmVFaWnrM96pEpH8N2uAAjunQ2GcwvEcR6V+D9lBVb+zYs5cMMwqy42TFB3XGioh00qdhD2oaWqjc1ciqqjpWV9WzeVcju5taaGvvOOJ919bWcuutt/Z5uw984APU1tYe8euLiBwuBUcPJg4v4KQRhYwqziU7nsGuxlY27mxk5dY61m2vp2p3E3uaW+no6Ps9TboLjvb2nm/K9sgjj1BSUtLn1xMROVp0qKoHZkZOZoyczBhlhdl0uNPU0s6evW3saW6jur6F7fXB4ay8rBgFOXEKsuPkZsYOeW7hxhtv5M0332TGjBlkZmZSUFDAqFGjWLp0KStWrOAjH/kImzZtorm5mRtuuIFrrrkG2D98yp49e7jgggt417vexfPPP8+YMWN4+OGHyc3N7Y8fjYgMYgoO4N/+sJwVW+oOa9v2Dg8e7p09DzOYNLKQmy6Y0nl+pGuQfOc732HZsmUsXbqUp59+mg9+8IMsW7as82uzd9xxB0OHDqWpqYnTTz+diy++mNLS0gP2sXbtWu6++25+/vOfc8kll/DAAw9w+eW6G6iIpJaC4wjFMoxYRhAKzv4gaW13Ntc2AZAVy6AgO05BTpz87DiZsYOPEM6ePfuAay1+/OMf89BDDwGwadMm1q5de1BwjB8/nhkzZgBw2mmnsWHDhhS8QxGRAyk4gP/94WlHfZ/uTktbR3BYa28bu5tbqWlsASA3M0Z7y4HnMvLz8zvnn376aZ544gleeOEF8vLyOPvss5Nei5Gdnd05H4vFaGpqOurvQ0SkKwVHipgZ2ZkxsjNjlBZk4+40tbazp7mNHXtaaPQ49fX1SbfdvXs3Q4YMIS8vj1WrVvHiiy/2c/UiIt1TcPQTMyMvK05eVpyMDGNLRzHvOONMpk+fTm5uLiNGjOhsO2fOHG677TZOOeUUJk2axBlnnBFh5SIiBzL3vn+VNN1UVFR41xs5rVy5kilTpkRST0eHs3pbPZmxDE4sy0/51d1RvlcRSV9mttjdK7qu13UcEcjIMIYXZtPYEpz/EBFJJwqOiAzJzyIrlkFVXTODodcnIscOBUdEMswYXpRNU0s79c3qdYhI+lBwRKgkL4useAbb1OsQkTSS0uAwszlmttrM1pnZjUmezzaze8PnXzKzceH6UjP7q5ntMbOfdNnmUjN7w8xeN7NHzWxYKt9DKmWYMaIwh6bWduqaW6MuR0SkV1IWHGYWA24BLgCmApea2dQuza4Gdrn7BOCHwHfD9c3AN4GvdtlnHLgZOMfdTwFeB65L1XvoDyV5mWTHY2yr26teh4ikhVT2OGYD69z9LXdvAe4BLurS5iLgznD+fuA8MzN3b3D35wgCJJGFj3wLvsNaBGxJ2TvoB2bGiKJsmlvb2d3Ufa+joKCgH6sSEeleKoNjDLApYbkyXJe0jbu3AbuBUrrh7q3A54E3CAJjKnD70Ss5GsW5meSo1yEiaSKVwZHsqraun4q9abO/sVkmQXDMBEYTHKq6qZu215jZIjNbVF1d3buK+9HXv/71zvtxmBl3/Pd/cvP3/p2zzzmXWbNmcfLJJ/Pwww9HXKWIyMFSOeRIJTA2Ybmcgw8r7WtTGZ6/KAZqetjnDAB3fxPAzO4DDjrpHrZZACyA4MrxHiv9841Q9UaPTfps5MlwwXe6fXrevHl88Ytf5Atf+AIACx96gFvvup/Cz13LrAlj2LlzJ2eccQYXXnih7hsuIgNKKoPjFWCimY0HNgPzgE92abMQuBJ4AZgLPOU9H6vZDEw1szJ3rwbeC6w86pX3g5kzZ7J9+3a2bNlCdXU1Q4YMYfrEcVx3/Q28sehFMuMxNm/ezLZt2xg5cmTU5YqIdEpZcLh7m5ldBzwGxIA73H25mX0LWOTuCwnOT9xlZusIehrz9m1vZhsITn5nmdlHgPe5+woz+zfgb2bWCmwErjriYnvoGaTS3Llzuf/++6mqqmLevHn84YF7qdtVwz2PPM20sUM5Yfz4pMOpi4hEKaWj47r7I8AjXdb9a8J8M/DxbrYd183624Dbjl6V0Zk3bx6f+cxn2LFjB8888wz33XcfY0ePxDNiLPzz42zcuDHqEkVEDqJh1SM0bdo06uvrGTNmDKNGjeKyyy7jwx/+MJd96FwmTZ3O5MmToy5RROQgCo6IvfHG/pPyw4YN44UXXqC+uZX1OxoYXZLLsILgLn979uyJqkQRkQNorKoBqCA7Tn5WnOr6vXR06LoOERlYFBwDUHA1eQ6t7R3sbGiJuhwRkQMM6uAYyFdpF+TEKcgOeh3tR9DrGMjvUUTS06ANjpycHHbu3DmgP1hHFOXQ1tFBTcPew9re3dm5cyc5OTlHuTIRGcwG7cnx8vJyKisrGYjDkSTavWcvOzZ1MKI4h4zDuII8JyeH8vLyFFQmIoPVoA2OzMxMxo8fH3UZh/Tq27v46K3P87X3T+LacyZEXY6IyOA9VJUuZh43hHMnD2fB397SzZ5EZEBQcKSBL7/3JHY3tXLHc+ujLkVERMGRDqaPKeZ9U0dw+7Pr2d2oXoeIREvBkSa+9N6TqN/bxs+ffSvqUkRkkFNwpIkpo4r44Mmj+OXf11OjiwJFJEIKjjTyxfMn0tjazs/+9mbUpYjIIKbgSCMTRxRy4amj+fXzG6muP7yLAkVEjpSCI83ccN5E9ra1c9sz6nWISDQUHGnmhLICPjqznN+8uJFtdbo7oIj0PwVHGrrhvIm0dTi3/nVd1KWIyCCk4EhDx5Xm8fHTyrn75U1sqW2KuhwRGWQUHGnqunMn4Dg/Ua9DRPqZgiNNlQ/J4xOnj+W+VzaxqaYx6nJEZBBRcKSxa8+ZQEaG8d9PrY26FBEZRBQcaWxUcS6fnH0cDyzZzIYdDVGXIyKDREqDw8zmmNlqM1tnZjcmeT7bzO4Nn3/JzMaF60vN7K9mtsfMftJlmywzW2Bma8xslZldnMr3MNB94ZwTyYwZP35SvQ4R6R8pCw4ziwG3ABcAU4FLzWxql2ZXA7vcfQLwQ+C74fpm4JvAV5Ps+hvAdnc/KdzvMykoP20ML8xh/pnj+J+lm1m3fU/U5YjIIJDKHsdsYJ27v+XuLcA9wEVd2lwE3BnO3w+cZ2bm7g3u/hxBgHT1aeA/ANy9w913pKb89PHZd59ATmaMm9XrEJF+kMrgGANsSliuDNclbePubcBuoLS7HZpZSTj7f81siZn93sxGdNP2GjNbZGaLBvp9xY9UaUE2V501jj++voUHl1RGXY6IHONSGRyWZJ0fRptEcaAc+Lu7zwJeAL6frKG7L3D3CnevKCsr6029ae3acyZw5gmlfPm+11ig0XNFJIVSGRyVwNiE5XJgS3dtzCwOFAM1PexzJ9AIPBQu/x6YdTSKTXf52XF++anT+eDJo/j3R1bx7T+toKOjpwwWETk8qQyOV4CJZjbezLKAecDCLm0WAleG83OBp9y920+78Lk/AGeHq84DVhzNotNZdjzGjy+dyfwzj+fnz67nq79/jdb2jqjLEpFjTDxVO3b3NjO7DngMiAF3uPtyM/sWsMjdFwK3A3eZ2TqCnsa8fdub2QagCMgys48A73P3FcDXw21+BFQDn0rVe0hHsQzj3y6cRllBNv/1lzXUNLZw62WzyMtK2T+1iAwy1sMf+MeMiooKX7RoUdRl9Lu7X36bbzz0BqeUl/DLq05nSH5W1CWJSBoxs8XuXtF1va4cP4ZdOvs4fnr5aazYWsfc255ns0bSFZGjQMFxjHv/tJHc9enZbK/fy8W3Ps+abfVRlyQiaU7BMQi844RS7vvsmXS4M/enz7NoQ09fXBMR6ZmCY5CYMqqIBz5/FsMKsrnsFy/xxIptUZckImlKwTGIjB2ax+8/dyaTRxby2d8s5r5XNh16IxGRLhQcg0xpQTa/+8wZnHViKf/8wOvc8td1DIZv1onI0aPgGITys+PcfuXpXDRjNN97bDXf+qOuMheR3tNVYYNUVjyDH14yg9L8bO74+3p27mnh+x8/lay4/pYQkZ4pOAaxjAzjmx+aQllhNt99dBW7Glv46eWnUZCt/xYi0j39eTnImRmfP/tE/nPuKTz/5k4++fMX2blnb9RlicgApuAQAC6pGMuCK05jzbZ65t72AptqGqMuSUQGKAWHdDpvygh++4/voKahhYt/+jwrt9ZFXdIhtbZ3sGZbPQtf28L3H1vN9Xe/ysNLN9Ouk/0iKaNBDuUga7fVM/+Ol9mzt41fzK/gHSd0e1PGfuPubK5tYnVVPau31QfTqnrerN5Da3vwfziWYZTkZrKzoYUTy/L5p3Mn8uFTRxPLSHa/MBE5lO4GOVRwSFJbapuYf8fLvF3TyE0XTGb8sHxK8rIozs2kODeTopw48VhqOqy7Glo6w2FVVT1rttWzpqqe+r1tnW1GF+dw0shCJo0sZPLIQk4aUciJZQVkxTJ4dHkVP35yLauq6jlhWD7XnTuBC08dnbJ6RY5VCg4FR5/tamjh6jtfYcnbtUmfL8yOUxQGSXFuJiV5++eLuiwX52ZSkhsET2FOnIwMo7m1nbXb9rCqqu6AnsT2+v0n54ty4kweWcSkMCQmhSFRnJvZY+0dHc7jK6q4+cl1rNxax7jSPK47dyIfmaEAEektBYeC47C0dzjrdzSwu6mV3U0twbSxld1NbdSGy3VNrdQ2toZtWqltaqWlrfs7D5oFobNnbxv7TkVkxTOYOLwgCIcR+3oSRYwoysbs8A81dXQ4f1m5jZufWMuKrXUcX5rHtedM4KMzx5CpABHpkYJDwdGvmlvb9wdJYqg0tlAXzhfnZTE57EUcPzQvpT0Bd+eJldu5+ck1LNtcx9ihuVx3zgQ+NqtcASLSDQWHgkMIAuSpVdu5+cm1vF65m/IhuVx7zgQunlWuq+ZFulBwKDgkgbvz9OpqfvTkWl7bVMuYkly+cM6JfPy0sYM+QPa2tbOroZWahpbg0djCroYW6ptbGTs0j6mjihg/LF/nigYBBYeCQ5Jwd55ZU83NT67l1bdrGV2cw+fPmcAlFeVkx2NRl3fE2juc3U1BCOxqbGHnnmBa0xCEQWIw1DS2ULOnhYaW9kPuNzuewaSRhUwZWcTU0UVMGVXE5FGFFOX0/KUFSS8KDgWH9MDdeXbtDm5+ci2LN+5iVHEOnz/7RC6pGEtOZv8FSEeH09jaTmNLG41722lsCecTpg0t7TS1tNGwN/G5A+drG1vY1RicU+ruWsi8rBhD87MYmp/FkLyszvn9y5kMzc9maH4mQ/KyyM+Os2FnAyu21LFyax0rttaxcms9NQ0tnfscOzT3gDCZOqqI8iG5R/QFB4mOgkPBIb3g7vx93U5ufnINr2zYxYiibD7/nhOZN/s4cjJjdHQ4zW3Bh3NTSzvNreF8a7DcdMByG00tHTS2ttHc0k27lnYaW/eHRFProf/aT5SbGSMvK0Zedoz8rDi5WcFySW4WQ/IzGRoGwpCEQCgtCKZHIxDdnW11ezuDJAiTOtbvaGDfR0thTrwzRKaMKmTqqGImjijo9eu7Ow0t7dQ1tVLX3EpdU1vCfCt1zfuX65vbOtvkZcWYMbYkeBxXwqji3CN+v4ONgkPBIX3g7rzw5k5+9ORaXl5fQ05mcDy/ubX7rxl3Jyue0fkBn5sZI7fLND87Hnz4Z8XIywrns+Pkd12XFSc/O9guPytObmaMjAF6VXxjSxurq+o7g2TFljpWVdXTGB4Gi2UYJ5blM2VUEccPzesMhs4P/n0BEYbDoUaQycuKUZSTSVFunMKc4ALVXY2trNhSR0t78G82oig7DJIhzBhbwinlxeRrJOgeRRIcZjYHuBmIAb9w9+90eT4b+DVwGrAT+IS7bzCzUuB+4HTgV+5+XZJ9LwROcPfph6pDwSFH4oU3d/LY8iqy4hnkJAmAA5azYuRlxsnJyiAvK05OPEMnkUMdHc7GmsbOIFkZhsqW3c3kZ8UoCi8ODQIg+PAPpkEg7F9/4HJhTrzbr1TvbWtnxZY6lm6q7Xxs3BkM4JlhcNKIwgN6JROHF6Z0iJqmlnY21zYFj11NbAnnaxpaqDh+CBecPJIJwwtT9vp91e/BYWYxYA3wXqASeAW41N1XJLT5AnCKu3/OzOYBH3X3T5hZPjATmA5M7xocZvYxYG64rYJDJI21d3i/jidW09DCa5tqeTUMktc21bK7qRWA/KwYJ5cXd/ZKZh5XwoiinF7t192paWhhc20QCJW7mjrng2nzAeeDIOh5jSzKoTAnzqqqegBOLMtnzvSRzJk2iuljiiI9PxRFcJwJ/B93f3+4fBOAu/9HQpvHwjYvmFkcqALKPCzKzK4CKhKDw8wKgEeBa4D7FBwiciTcg9EREnslK7bU0RYeHxtdnMOM44JeyanlJTgc0FvYXLs/ILoeyszLijGmJJfRJbmMGZLLmJLwMSRYN6Iwu7NHuq2umcdXbOPRZVt58a0a2jucMSW5vH/aSOZMH8lpxw/p9wE7uwuOVB7gGwNsSliuBN7RXRt3bzOz3UApsKOH/f5f4L+AHm8YYWbXEIQLxx13XJ8KF5HBw8w4oayAE8oK+NisciAY+WD5lt28+vb+MHnkjaqDth1WkMXoklwmjSjk3EnDDwqIkrzMXvcYRhTlcMUZx3PFGcezq6GFJ1Zu47HlVfzmpY3c8ff1DCvI5n3TRjBn2kjOOKE00uuNUhkcyX5aXbs3vWmzv7HZDGCCu3/JzMb19OLuvgBYAEGPo8dKRUQS5GTGOO34oZx2/NDOddX1e1m2eTfxmHX2IlL1Ve0h+Vl8vGIsH68Yy569bTy9ejuPLqvi4Vc387uX3qYoJ875U0bw/ukjeffEMnKz+veao1QGRyUwNmG5HNjSTZvK8FBVMVDTwz7PBE4zsw0EtQ83s6fd/eyjVbSISDJlhdmcM3l4v79uQXacD50ymg+dMprm1naeW7uDR5dX8cTKbTz46mZyM2OcPamMOdNHcs7k4f1yEWYqg+MVYKKZjQc2A/OAT3ZpsxC4EniB4GT3U97DSRd3/ynwU4Cwx/FHhYaIDBY5mTHOnzqC86eOoLW9g5fX1/DosioeW17Fn5dVkRXL4J0TSpkzfSTnTxlBaUF2SupI9ddxPwD8iODruHe4+7fN7FvAIndfaGY5wF0E36CqAea5+1vhthuAIiALqAXe1+UbWeMIgiM1J8c72uGFW6BgOJw6r2/bioj0o44O59VNtWGAbGVTTRMZBrPHD+WWT8467ADRBYB9DQ53+OUFUPs2XP8qxFOT3CIiR5O7s2JrHY8tq2Lx27u469PvOOwLRaP4VlV6M4P3/DPc9VFY+juo+FTUFYmIHJKZMW10MdNGF6fsNXRJa09OOAfKT4dnfwBtLYduLyIyCCg4emIG7/k67H4bXr8n6mpERAYEBcehTDgfRs+Ev30f2lujrkZEJHIKjkPZ1+uo3Qhv/D7qakREIqfg6I2T5sDIk8NeR1vU1YiIRErB0Rv7eh01b8LyB6OuRkQkUr0KDjO7wcyKLHC7mS0xs/elurgBZdIHYfg0+Nv3gosDRUQGqd72OD7t7nXA+4Ay4FPAd3re5BiTkQHv+RrsWAMr/ifqakREItPb4Nh32eEHgF+6+2skH9n22DblIiibDM98Dzr6fgtREZFjQW+DY7GZPU4QHI+ZWSEw+D45MzLg3V+D6pWw6g9RVyMiEoneBsfVwI3A6e7eCGQSHK4afKZ9FEonwjP/qV6HiAxKvQ2OM4HV7l5rZpcD/wLsTl1ZA1hGLOh1bFsGa/4cdTUiIv2ut8HxU6DRzE4F/hnYCPw6ZVUNdNMvhqEnwDPfDUbRFREZRHobHG3hDZYuAm5295uBwtSVNcDF4vAPX4Wtr8Hax6OuRkSkX/U2OOrN7CbgCuBPZhYjOM8xeJ1yCZQcr16HiAw6vQ2OTwB7Ca7nqALGAN9LWVXpIJYJ//AV2LwY3nwy6mpERPpNr4IjDIvfAsVm9iGg2d0H7zmOfU69FIrHwtPqdYjI4NHbIUcuAV4GPg5cArxkZnNTWVhaiGfBu74ElS/D+meirkZEpF/09lDVNwiu4bjS3ecDs4Fvpq6sNDLzcigcHVzXISIyCPQ2ODLcfXvC8s4+bHtsi2cHvY6Nf4cNz0VdjYhIyvX2w/9RM3vMzK4ys6uAPwGPpK6sNDNrPhSMhKcH17iPIjI49fbk+NeABcApwKnAAnf/+qG2M7M5ZrbazNaZ2Y1Jns82s3vD518ys3Hh+lIz+6uZ7TGznyS0zzOzP5nZKjNbbmYD45M6MwfeeQNseBY2Ph91NSIiKdXrw03u/oC7f9ndv+TuDx2qfXitxy3ABcBU4FIzm9ql2dXALnefAPwQ+G64vpngHMpXk+z6++4+GZgJvNPMLujte0ip066C/DKd6xCRY16PwWFm9WZWl+RRb2Z1h9j3bGCdu7/l7i3APQRXnie6CLgznL8fOM/MzN0b3P05ggDp5O6N7v7XcL4FWAKU9+qdplpWHpx1Pbz1V9j0ctTViIikTI/B4e6F7l6U5FHo7kWH2PcYYFPCcmW4Lmkbd28jGDixtDeFm1kJ8GEg6dV3ZnaNmS0ys0XV1dW92eWRO/1qyCtVr0NEjmmp/GZUshs9db1KrjdtDt6xWRy4G/ixu7+VrI27L3D3CnevKCsrO2SxR0VWPpz1T7DuL8EV5SIix6BUBkclMDZhuRzY0l2bMAyKgZpe7HsBsNbdf3QU6jy6Tv9HyB0S3CVQROQYlMrgeAWYaGbjzSwLmAcs7NJmIXBlOD8XeCochbdbZvb/CALmi0e53qMjuxDOvDa4V8fW16KuRkTkqEtZcITnLK4DHgNWAve5+3Iz+5aZXRg2ux0oNbN1wJcJ7jIIgJltAH4AXGVmlWY21czKCa5inwosMbOlZvaPqXoPh232NZBTrHMdInJMiqdy5+7+CF0uFHT3f02YbyYY/yrZtuO62W2y8yIDS04xnPEFePo/oGoZjJwedUUiIkeNhg1JlXd8FrKL4G861yEixxYFR6rkDgnCY8XDsH1l1NWIiBw1Co5UOuMLwVd0//b9qCsRETlqFByplDcUZn8Glj0A1WuirkZE5KhQcKTamddBZi48+19RVyIiclQoOFItf1gwFMkb98HON6OuRkTkiCk4+sNZ10MsC579QdSViIgcMQVHfygYDhWfhtfuhl0boq5GROSIKDj6y1nXQ0ZcvQ4RSXsKjv5SNCq42dPS30Ht21FXIyJy2BQc/emdN4AZPPfDqCsRETlsCo7+VDwGZl4BS+6C3ZVRVyMiclgUHP3tXV8C74BXfhF1JSIih0XB0d9KxsJJ7w/OdbS3RV2NiEifKTiiMGs+7NkGax+PuhIRkT5TcERhwnuhYCQs+XXUlYiI9JmCIwqxOMz4JKx9DOq63oZdRGRgU3BEZeblwUnypb+LuhIRkT5RcESl9EQY9w/w6m+goyPqakREek3BEaVZV8Ku9bDxuagrERHpNQVHlKZ8GHJKdJJcRNKKgiNKmTlwyiWwYiE01kRdjYhIryg4ojZrPrTvhTd+H3UlIiK9ktLgMAxTptoAABHMSURBVLM5ZrbazNaZ2Y1Jns82s3vD518ys3Hh+lIz+6uZ7TGzn3TZ5jQzeyPc5sdmZql8Dyk38mQYPTM4XOUedTUiIoeUsuAwsxhwC3ABMBW41Mymdml2NbDL3ScAPwS+G65vBr4JfDXJrn8KXANMDB9zjn71/WzWfNi2DLa8GnUlIiKHlMoex2xgnbu/5e4twD3ARV3aXATcGc7fD5xnZubuDe7+HEGAdDKzUUCRu7/g7g78GvhICt9D/5g+FzLzdJJcRNJCKoNjDLApYbkyXJe0jbu3AbuB0kPsM3E88mT7BMDMrjGzRWa2qLq6uo+l97OcIpj2UXjjfmhpiLoaEZEepTI4kp176HoQvzdtDqu9uy9w9wp3rygrK+thlwPEzCugpR6W/0/UlYiI9CiVwVEJjE1YLge6DszU2cbM4kAx0NP3UivD/fS0z/R03BlQOlGHq0RkwEtlcLwCTDSz8WaWBcwDFnZpsxC4MpyfCzwVnrtIyt23AvVmdkb4bar5wMNHv/QImAUnyTe9CNWro65GRKRbKQuO8JzFdcBjwErgPndfbmbfMrMLw2a3A6Vmtg74MtD5lV0z2wD8ALjKzCoTvpH1eeAXwDrgTeDPqXoP/e7USyEjDq/eFXUlIiLdsh7+wD9mVFRU+KJFi6Iuo3fuvQI2Pg9fXgnxrKirEZFBzMwWu3tF1/W6cnygmTUfGnfAmmOnIyUixxYFx0Bz4rlQNEYnyUVkwFJwDDQZseAmT+uehNpNh24vItLPFBwD0YzLgunS30Zbh4hIEgqOgWjI8XDiOeHdAdujrkZE5AAKjoFq1nzYvQneejrqSkREDqDgGKgmfQByh+okuYgMOAqOgSqeHVwQuOpP0LAj6mpERDopOAayWVdARyu8dk/UlYiIdFJwDGTDp0D5bN0dUEQGFAXHQDdrPuxYDZtejroSERFAwTHwTfsoZBXAqzpJLiIDg4JjoMsugOkfg2UPQnNd1NWIiCg40sKsK6G1EZY/GHUlIiIKjrQw5jQYPlXXdIjIgKDgSAf77g64eTFULYu6GhEZ5BQc6eKUT0AsS3cHFJHIKTjSRd5QmPwheP1eaG2OuhoRGcQUHOlk1nxo2gWr/hh1JSIyiCk40sn490DJcTpJLiKRUnCkk4wMmDkf1j8DNeujrkZEBikFR7qZ8UmwjOAmTyIiEUhpcJjZHDNbbWbrzOzGJM9nm9m94fMvmdm4hOduCtevNrP3J6z/kpktN7NlZna3meWk8j0MOMVjYML5wW1l29uirkZEBqGUBYeZxYBbgAuAqcClZja1S7OrgV3uPgH4IfDdcNupwDxgGjAHuNXMYmY2BrgeqHD36UAsbDe4zJoP9VvhzSejrkREBqFU9jhmA+vc/S13bwHuAS7q0uYi4M5w/n7gPDOzcP097r7X3dcD68L9AcSBXDOLA3nAlhS+h4HppDmQX6aT5CISiVQGxxhgU8JyZbguaRt3bwN2A6Xdbevum4HvA28DW4Hd7v54shc3s2vMbJGZLaqurj4Kb2cAiWUG5zpW/xnqt0VdjYgMMqkMDkuyruvdiLprk3S9mQ0h6I2MB0YD+WZ2ebIXd/cF7l7h7hVlZWV9KDtNzJwP3g6v/S7qSkRkkEllcFQCYxOWyzn4sFJnm/DQUzFQ08O25wPr3b3a3VuBB4GzUlL9QDdsAhx3lu4OKCL9LpXB8Qow0czGm1kWwUnshV3aLASuDOfnAk+5u4fr54XfuhoPTAReJjhEdYaZ5YXnQs4DVqbwPQxss+ZDzVuw8e9RVyIig0jKgiM8Z3Ed8BjBh/t97r7czL5lZheGzW4HSs1sHfBl4MZw2+XAfcAK4FHgWndvd/eXCE6iLwHeCOtfkKr3MOBNvQiyi2CJBj4Ukf5jPggOc1RUVPiiRYuiLiM1/vjl4JqOr6yG3JKoqxGRY4iZLXb3iq7rdeV4ups1H9qa4Y3fR12JiAwSCo50N3oGjDxF13SISL+JR12AHAWz5sMjX4UtS4MgiVp7KzTVQnNtz9N4FuQNCy5mzC8N58Pl3KEQ039PkYFIv5nHgpPnwuP/EvQ6Dic4OjqgvSV8tIbTvfvnWxoPHQLNtcG9QppqobWh59fLzIec4mDfjTs5+PIeAAvO2RwULGVBuOSV7g+ZvHBZQSPSL/SbdizIHRJ8w+q1e6BuS0IIdA2DhPm2hOe9ve+vmZkHOSXBh3tOCZQcD6NOPXBdd9N41v79dLQHgdOwAxp3QEN1OL/zwPkd66DhBWiqAe9IXlNOCRQMh6EnwvDJULbvMQkycw/vZysiB1FwHCvOvBa2r4S6zcG9yWNZEM8J/rKPZQXDlBwwTZzP7mZ9OJ+Z1/OH/5HIiIU9h2G9a9/RHvRqGqrDoNmxf9qwA/Zsgx1rYd0T0NEabmQwZBwMnxKESNmUIFiGnaRAETkMCo5jxahT4XPPRl1F6mXEgsNW+aU9t2tvDS6O3L4Sqlftn659HDrC4egtIwiUsjBQhk8JeijDToLMwTVav0hfKDjk2BTLDHsXkw5c39YSBEr1Sti+av907WNdAmV8ECLDJ4fBchIUjw0OC1qyodREBg8Fhwwu8awgDIZPDu72sk9bC9S8eXAPZc2jB54DiudC0ejghlpF5eE0fOybzylWuMgxTcEhAmGgTAkeidr2ws43Ycea4PxR3RbYXRnMv/U07Kk6+GR9VkEQLp1hsi9gRu+fzy7st7fWb9yDc1AdrcGhwo62cJpsuW3/eoDsgmD4nJziYHq0zqFJSig4RHoSz4YRU4NHMu1tQXjs3gx1leF0y/757Stgz3YO+spxdnEQJPnDgi8xxLODaWZOuJywrlfT3AOXO9qhrQlam/dPWxuDUQZam7pMe9MmnLa3HPihf0BQtCb9ER3ezz0nDJKiJNPiIHi7e27fss5TpYyCQ+RIxOJQXB48eEfyNm0twa1+6zbvD5i6LcF8405o2RP0bNqaD5529NN95S0WfMMsnhN8i25fgO1blzskCKRYFmRkBu87IzM4l5QRD6fJlhPbdbMdwN56aK6DveGjOcm0vmr/csueQ7+nzDwoHAmFo6BgRDDdt1yYsHws9v5STMEhkmrxLBhyfPDoq/a24GLMfUHS2tR9yCROMzKCXkhmzv5pZt6BYZA43fcBni462oOwSRoyu4NpY00QNvVVsPU1WPNY8otTswq6BMvIhIBJCJ7sgv5/nwOUgkNkIIvFg0dWftSVDCwZseCaor6OCL23PgyTrQnTbfuXNy8Opm1NB2+bVXhgsBwUNoMnYBQcIjJ4ZBcGj2ETu2/jHvRYDgiYqv3Le7ZB5SthwDQfvP0gCBgFh4hIIrPg2105xQdfB5TIPTgsVl8VfEHisAJmxP4gSTom27BgXU7JgPqKt4JDRORwmO0/XDZ8cvft9gXMnm0H92D2Bc7mxcGQOS31yfeRkbl/YM+uA3wmGwA0pyQ4z5UiCg4RkVRKDJieejAQfCV63wCfjTugYWfCWGzV4XM7YMurwXRvXTevGQsDpgyufvyoHxZTcIiIDBSZOcEFosVjete+be/+MEkMln0jTTfWBN+mO8oUHCIi6SqeHY5IMLpfX1a3jhURkT5RcIiISJ8oOEREpE9SGhxmNsfMVpvZOjO7Mcnz2WZ2b/j8S2Y2LuG5m8L1q83s/QnrS8zsfjNbZWYrzezMVL4HERE5UMqCw8xiwC3ABcBU4FIz6zrE6NXALnefAPwQ+G647VRgHsEdE+YAt4b7A7gZeNTdJwOnAitT9R5ERORgqexxzAbWuftb7t4C3ANc1KXNRcCd4fz9wHlmZuH6e9x9r7uvB9YBs82sCHg3cDuAu7e4e20K34OIiHSRyuAYA2xKWK4M1yVt4+5twG6gtIdtTwCqgV+a2atm9gszSzr6m5ldY2aLzGxRdXX10Xg/IiJCaoMj2cAq3ss23a2PA7OAn7r7TKABOOjcCYC7L3D3CnevKCsr633VIiLSo1ReAFgJjE1YLge2dNOm0sziQDFQ08O2lUClu78Urr+fboIj0eLFi3eY2cbDeRPAMGDHYW7b39KpVkivetOpVkivetOpVkiveo+01qQ3kUllcLwCTDSz8cBmgpPdn+zSZiFwJfACMBd4yt3dzBYCvzOzHwCjgYnAy+7ebmabzGySu68GzgNWHKoQdz/sLoeZLXL3isPdvj+lU62QXvWmU62QXvWmU62QXvWmqtaUBYe7t5nZdcBjQAy4w92Xm9m3gEXuvpDgJPddZraOoKcxL9x2uZndRxAKbcC17t4e7vqfgN+aWRbwFvCpVL0HERE5WErHqnL3R4BHuqz714T5ZuDj3Wz7beDbSdYvBdIi7UVEjkW6cvzQFkRdQB+kU62QXvWmU62QXvWmU62QXvWmpFZz7/pFJxERke6pxyEiIn2i4BARkT5RcHTjUAM0DiRmNtbM/hoO+rjczG6IuqZDMbNYePX/H6Ou5VDSaWBNM/tS+H9gmZndbWY5UdeUyMzuMLPtZrYsYd1QM/uLma0Np0OirDFRN/V+L/y/8LqZPWRmJVHWuE+yWhOe+6qZuZkNOxqvpeBIopcDNA4kbcBX3H0KcAZw7QCvF+AG0meAyrQYWNPMxgDXAxXuPp3ga/Dzoq3qIL8iGLg00Y3Ak+4+EXiSXlzU249+xcH1/gWY7u6nAGuAm/q7qG78ioNrxczGAu8F3j5aL6TgSK43AzQOGO6+1d2XhPP1BB9svbxpcf8zs3Lgg8Avoq7lUNJwYM04kBuOxJDHwaM1RMrd/0ZwzVaixMFO7wQ+0q9F9SBZve7+eDi2HsCLBCNbRK6bny0EI4//MwcP+XTYFBzJ9WaAxgEpvKfJTOClnltG6kcE/5E7oi6kF3o9sGbU3H0z8H2Cvyy3Arvd/fFoq+qVEe6+FYI/goDhEdfTF58G/hx1Ed0xswuBze7+2tHcr4Ijud4M0DjgmFkB8ADwRXevi7qeZMzsQ8B2d18cdS291OuBNaMWnhu4CBhPMFRPvpldHm1Vxy4z+wbBYeLfRl1LMmaWB3wD+NdDte0rBUdyvRmgcUAxs0yC0Pituz8YdT09eCdwoZltIDgEeK6Z/SbaknqUbGDNWRHW05PzgfXuXu3urcCDwFkR19Qb28xsFEA43R5xPYdkZlcCHwIu84F7MdyJBH9EvBb+vpUDS8xs5JHuWMGRXOcAjeGYWPMIBmQckMKbX90OrHT3H0RdT0/c/SZ3L3f3cQQ/16fcfcD+VezuVcAmM5sUrurVwJoReRs4w8zywv8T5zFAT+R3sW+wU8LpwxHWckhmNgf4OnChuzdGXU933P0Ndx/u7uPC37dKYFb4f/qIKDiSCE987RugcSVwn7svj7aqHr0TuILgr/el4eMDURd1DNk3sObrwAzg3yOuJ6mwV3Q/sAR4g+D3e0ANj2FmdxOMhj3JzCrN7GrgO8B7zWwtwbd/vhNljYm6qfcnQCHwl/B37bZIiwx1U2tqXmvg9rJERGQgUo9DRET6RMEhIiJ9ouAQEZE+UXCIiEifKDhERKRPFBwiA5iZnZ0OIwjL4KLgEBGRPlFwiBwFZna5mb0cXhD2s/B+I3vM7L/MbImZPWlmZWHbGWb2YsL9HIaE6yeY2RNm9lq4zYnh7gsS7gfy2/CqcJHIKDhEjpCZTQE+AbzT3WcA7cBlQD6wxN1nAc8A/zvc5NfA18P7ObyRsP63wC3ufirBGFNbw/UzgS8S3BvmBIKRAkQiE4+6AJFjwHnAacArYWcgl2Cgvg7g3rDNb4AHzawYKHH3Z8L1dwK/N7NCYIy7PwTg7s0A4f5edvfKcHkpMA54LvVvSyQ5BYfIkTPgTnc/4E5wZvbNLu16Gt+np8NPexPm29HvrURMh6pEjtyTwFwzGw6d99A+nuD3a27Y5pPAc+6+G9hlZv8Qrr8CeCa8f0qlmX0k3Ed2eD8FkQFHf7mIHCF3X2Fm/wI8bmYZQCtwLcFNn6aZ2WJgN8F5EAiGDr8tDIa3gE+F668AfmZm3wr38fF+fBsivabRcUVSxMz2uHtB1HWIHG06VCUiIn2iHoeIiPSJehwiItInCg4REekTBYeIiPSJgkNERPpEwSEiIn3y/wHpr4cUZxK1yAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, sen_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[many of the churches work together for townwide projects under the banner of churches together in stevenage], target=[many of the churches work together for townwide projects calliing themselves churches together in stevenage], predicted=[]\n",
      "src=[tracking northwestward the depression moved ashore near fort walton beach early on september and shortly thereafter it dissipated over southeastern alabama], target=[tracking northwestward the depression moved ashore near fort walton beach early on september and shortly thereafter it fell apart over southeastern alabama], predicted=[]\n",
      "src=[in return romania ceded three southern districts of bessarabia to russia and acquired dobruja], target=[romania ceded three southern districts of bessarabia to russia in return for dorbuja], predicted=[]\n",
      "src=[in march the world wrestling federation purchased world championship wrestling], target=[in march the world wrestling federation bought world championship wrestling], predicted=[]\n",
      "src=[the empire of nicaea succeeded in capturing constantinople and the rest of the latin empire thus reestablishing the byzantine empire], target=[the byzantine empire was reestablished after the empire of nicaea succeeded in capturing constantinople and the rest of the latin empire], predicted=[]\n",
      "src=[word processing templates enable the ability to bypass the initial setup and configuration time necessary to create standardized documents such as a resume], target=[word processing templates enable the ability to bypass the first setup and layout time necessary to create systematize documents such as a resume], predicted=[]\n",
      "src=[subsequent visits reported seeing the flag flying from places of honor], target=[during subsequent visits it was reported the flag flew from places of honor], predicted=[]\n",
      "src=[in march the world wrestling federation purchased world championship wrestling], target=[in march the world fighting federation got to own world sporting event fighting], predicted=[]\n",
      "src=[this led scientists to reexamine the old photos again and the satellite was finally found in the images], target=[this led scientists to reexamine the old photos again and the satellite was finally found in the images], predicted=[]\n",
      "src=[in roy was selected as the greatest goaltender in nhl history by a panel of writers coupled with a simultaneous fan poll], target=[in roy was picked out as the greatest goaltender in nhl history by a panel of writers as well a by a fan poll that was taken at the same time], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,sen_tokenizer,trainX,train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
