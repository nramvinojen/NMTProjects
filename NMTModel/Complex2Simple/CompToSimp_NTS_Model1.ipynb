{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "import string\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "               # open the file as read only\n",
    "               file = open(filename, mode='rt', encoding='utf-8')\n",
    "               # read all text\n",
    "               text = file.read()\n",
    "               # close the file\n",
    "               file.close()\n",
    "               return text\n",
    "def to_lines(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    return lines\n",
    " \n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "               lines = doc.strip().split('\\n')\n",
    "               pairs = [line.split('\\t') for line in  lines]\n",
    "               return pairs\n",
    " \n",
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "   cleaned = list()\n",
    "   # prepare regex for char filtering\n",
    "   re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "   # prepare translation table for removing punctuation\n",
    "   table = str.maketrans('', '', string.punctuation)\n",
    "   for pair in lines:\n",
    "      clean_pair = list()\n",
    "      for line in pair:\n",
    "         # normalize unicode characters\n",
    "         line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "         line = line.decode('UTF-8')\n",
    "         # tokenize on white space\n",
    "         line = line.split()\n",
    "         # convert to lowercase\n",
    "         line = [word.lower() for word in line]\n",
    "         # remove punctuation from each token\n",
    "         line = [word.translate(table) for word in line]\n",
    "         # remove non-printable chars form each token\n",
    "         line = [re_print.sub('', w) for w in line]\n",
    "         # remove tokens with numbers in them\n",
    "         line = [word for word in line if word.isalpha()]\n",
    "         # store as string\n",
    "         clean_pair.append(' '.join(line))\n",
    "      cleaned.append(clean_pair)\n",
    "   return array(cleaned)\n",
    " \n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "               dump(sentences, open(filename, 'wb'))\n",
    "               print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = 'dev_en.txt'\n",
    "doc_in = load_doc(filename)\n",
    "filename = 'dev_sen.txt'\n",
    "doc_out = load_doc(filename)\n",
    "lines_in = to_lines(doc_in)\n",
    "lines_out = to_lines(doc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lines_in = np.asarray(lines_in)\n",
    "lines_out = np.asarray(lines_out)\n",
    "\n",
    "pairs = np.column_stack((lines_out, lines_in))\n",
    "pairs = pairs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marin, Mendocino, Lake, Napa, Solano and Contra Costa are all adjacent countries.',\n",
       " 'Adjacent counties are Marin ( to the south ) , Mendocino ( to the north ) , Lake ( northeast ) , Napa ( to the east ) , and Solano and Contra Costa ( to the southeast ) .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[2]\n",
    "#type(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SimpleEnglish-English.pkl\n"
     ]
    }
   ],
   "source": [
    "# clean sentences\n",
    "clean_pairs = clean_pairs(pairs[:200])\n",
    "# save clean pairs to file\n",
    "save_clean_data(clean_pairs, 'SimpleEnglish-English.pkl')\n",
    "# spot check\n",
    "#for i in range(100):\n",
    "  # print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SimpleEnglish-English-both.pkl\n",
      "Saved: SimpleEnglish-English-train.pkl\n",
      "Saved: SimpleEnglish-English-val.pkl\n",
      "Saved: SimpleEnglish-English-test.pkl\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    " \n",
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    " \n",
    "# load dataset\n",
    "raw_dataset = load_clean_sentences('SimpleEnglish-English.pkl')\n",
    " \n",
    "# reduce dataset size\n",
    "n_sentences = 200\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test \n",
    "train, val, test = dataset[:150], dataset[150:170], dataset[170:] #Added Validation set - avs\n",
    "# save\n",
    "save_clean_data(dataset, 'SimpleEnglish-English-both.pkl')\n",
    "save_clean_data(train, 'SimpleEnglish-English-train.pkl')\n",
    "save_clean_data(val, 'SimpleEnglish-English-val.pkl')\n",
    "save_clean_data(test, 'SimpleEnglish-English-test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# load datasets\n",
    "dataset = load_clean_sentences('SimpleEnglish-English-both.pkl')\n",
    "train = load_clean_sentences('SimpleEnglish-English-train.pkl')\n",
    "val = load_clean_sentences('SimpleEnglish-English-val.pkl') #added clean for val - avs\n",
    "test = load_clean_sentences('SimpleEnglish-English-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "# max sentence length\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleEng Vocabulary Size: 517\n",
      "SimpleEng Max Length: 44\n",
      "English Vocabulary Size: 288\n",
      "English Max Length: 35\n"
     ]
    }
   ],
   "source": [
    "# prepare SimpleEng tokenizer\n",
    "sen_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "sen_vocab_size = len(sen_tokenizer.word_index) + 1\n",
    "sen_length = max_length(dataset[:, 0])\n",
    "print('SimpleEng Vocabulary Size: %d' % sen_vocab_size)\n",
    "print('SimpleEng Max Length: %d' % (sen_length))\n",
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 1])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 1])\n",
    "trainY = encode_sequences(sen_tokenizer, sen_length, train[:, 0])\n",
    "trainY = encode_output(trainY, sen_vocab_size)\n",
    "# prepare validation data\n",
    "valX = encode_sequences(eng_tokenizer, eng_length, val[:, 1]) #added tokeniser for val set - avs\n",
    "valY = encode_sequences(sen_tokenizer, sen_length, val[:, 0])\n",
    "valY = encode_output(valY, sen_vocab_size)\n",
    "# prepare test data\n",
    "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 1])\n",
    "testY = encode_sequences(sen_tokenizer, sen_length, test[:, 0])\n",
    "testY = encode_output(testY, sen_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 256)           73728     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 44, 256)           525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 44, 517)           132869    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 44, 517)           0         \n",
      "=================================================================\n",
      "Total params: 1,257,221\n",
      "Trainable params: 1,257,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed, Dense, Dropout\n",
    "#from keras.utils import plot_model\n",
    "#import pydot \n",
    "\n",
    "\n",
    "# define NMT model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    model.add(Dropout(0.3))\n",
    "    return model\n",
    " \n",
    "# define model\n",
    "model = define_model(eng_vocab_size, sen_vocab_size, eng_length, sen_length, 256)\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy')\n",
    "# summarize defined model\n",
    "print(model.summary())\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 150 samples, validate on 20 samples\n",
      "Epoch 1/15\n",
      " - 4s - loss: 9.0189 - val_loss: 5.8546\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.85457, saving model to model.h5\n",
      "Epoch 2/15\n",
      " - 1s - loss: 8.3637 - val_loss: 3.0599\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.85457 to 3.05994, saving model to model.h5\n",
      "Epoch 3/15\n",
      " - 2s - loss: 6.7171 - val_loss: 2.8628\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.05994 to 2.86285, saving model to model.h5\n",
      "Epoch 4/15\n",
      " - 1s - loss: 6.6760 - val_loss: 2.7656\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.86285 to 2.76562, saving model to model.h5\n",
      "Epoch 5/15\n",
      " - 1s - loss: 6.6027 - val_loss: 2.6576\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.76562 to 2.65759, saving model to model.h5\n",
      "Epoch 6/15\n",
      " - 2s - loss: 6.5008 - val_loss: 2.7203\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.65759\n",
      "Epoch 7/15\n",
      " - 2s - loss: 6.5283 - val_loss: 2.6417\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.65759 to 2.64168, saving model to model.h5\n",
      "Epoch 8/15\n",
      " - 1s - loss: 6.5173 - val_loss: 2.6224\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.64168 to 2.62242, saving model to model.h5\n",
      "Epoch 9/15\n",
      " - 1s - loss: 6.4482 - val_loss: 2.6262\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.62242\n",
      "Epoch 10/15\n",
      " - 1s - loss: 6.5614 - val_loss: 2.5927\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.62242 to 2.59268, saving model to model.h5\n",
      "Epoch 11/15\n",
      " - 1s - loss: 6.6252 - val_loss: 2.5536\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.59268 to 2.55362, saving model to model.h5\n",
      "Epoch 12/15\n",
      " - 2s - loss: 6.4943 - val_loss: 2.5266\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.55362 to 2.52660, saving model to model.h5\n",
      "Epoch 13/15\n",
      " - 1s - loss: 6.4769 - val_loss: 2.4894\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.52660 to 2.48935, saving model to model.h5\n",
      "Epoch 14/15\n",
      " - 2s - loss: 6.3293 - val_loss: 2.4558\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.48935 to 2.45579, saving model to model.h5\n",
      "Epoch 15/15\n",
      " - 2s - loss: 6.4466 - val_loss: 2.4181\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.45579 to 2.41810, saving model to model.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# fit model\n",
    "filename = 'model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(trainX, trainY, epochs=15, batch_size=64, validation_data=(valX, valY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "# generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [np.argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "# evaluate the skill of the model\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        # translate encoded source text\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, sen_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "        predicted.append(translation.split())\n",
    "    # calculate BLEU score\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src=[singles competition after years in the tag team division hardy took on the undertaker in a ladder match for the undisputed championship], target=[hardy after years in the tag team division took on the undertaker in a ladder match for the championship], predicted=[the]\n",
      "src=[anthony mcgill is the principal clarinetist for the metropolitan opera], target=[anthony mcgill is the main clarinetist for the metropolitan opera], predicted=[]\n",
      "src=[in march the world wrestling federation purchased world championship wrestling], target=[in march the world wrestling federation bought world championship wrestling], predicted=[]\n",
      "src=[the west coast blues is a type of blues music characterized by jazz and jump blues influences strong pianodominated sounds and jazzy guitar solos which originated from texas blues players relocated to california in the], target=[the west coast blues is a sort of blues music represented by jazz and jump blues effects strong pianodominated sounds and jazzy music instrument with solos which originated from texas blues players put in a different place to california in the], predicted=[the]\n",
      "src=[it is particularly famous for the cultivation of kiwifruit], target=[it is mostly famous for the growing of kiwifruit], predicted=[]\n",
      "src=[in roy was selected as the greatest goaltender in nhl history by a panel of writers coupled with a simultaneous fan poll], target=[in roy was chosen as the best goaltender in nhl history by a panel of writers and a fan poll], predicted=[the]\n",
      "src=[anthony mcgill is the principal clarinetist for the metropolitan opera], target=[anthony mcgill is the principal clarinetist for the metropolitan opera], predicted=[]\n",
      "src=[they would later return to the revived series in the christmas special the next doctor introducing two new variants of the race the cybershades and the cyberking], target=[they would return to the series in the christmas special the next doctor introducing two new variants of the race], predicted=[the]\n",
      "src=[history landsberg prison which is in the town s western outskirts was completed in], target=[history landsberg prison which is on the western side of town was completed in], predicted=[]\n",
      "src=[agriculture locals grow seasonal crops such as maize makai and wheat kanak], target=[locals grow crops such as maize and wheat], predicted=[]\n",
      "BLEU-1: 0.000000\n",
      "BLEU-2: 0.000000\n",
      "BLEU-3: 0.000000\n",
      "BLEU-4: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\PyTfCPU\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,sen_tokenizer,trainX,train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
